{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2495b66-9818-432d-a8fd-a537a627835e",
   "metadata": {},
   "source": [
    "Это на случай, если я завтра не проснусь и не доделаю тетрадку. Пока тут просто много плохого кода, но всё работает, я бы сказал, что достаточно неплохо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d2e42-2b92-4fbe-8c66-6dd15638f6f5",
   "metadata": {},
   "source": [
    "Google API это творение Дьявола, не иначе, поэтому большая часть кода для создания документа, нормальной записи со всем форматированием была честно украдена с просторов StackOverflow, ссылку я забыл, очевидно. Есть даже функционал для вставки всяких картинок, ну а вдруг. Самое главное там - посмотреть на функции вставки и форматирвоания текста, потому что обе они завязаны на индексе, что на самом деле очень сильно мешает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064aff22-a66b-4eaa-8f09-bb6e2684f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle\n",
    "import os.path\n",
    "import sys\n",
    "import random\n",
    "import wikipediaapi\n",
    "import uuid\n",
    "from datetime import date\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "DEBUG = 0\n",
    "if DEBUG:\n",
    "    import json\n",
    "\n",
    "class Covid19Docs:\n",
    "    def __init__(self):\n",
    "        # If modifying these scopes, delete the file token.pickle.\n",
    "        self.DRIVE_SCOPES = ['https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/documents']\n",
    "        self.creds = None\n",
    "        # Add all your created templates in the below list.\n",
    "        self.templates = ['1a0C3AQ290uc0yFcVhLD36sj12mQdmv_VnSjh4WhnNvQ']\n",
    "        self.drive_service = None\n",
    "        self.docs_service = None\n",
    "        self.wiki = wikipediaapi.Wikipedia(language='en', extract_format=wikipediaapi.ExtractFormat.WIKI)\n",
    "        self.covid19_wiki = self.wiki.page(\"Coronavirus_disease_2019\")\n",
    "\n",
    "\n",
    "        # The file token.pickle stores the user's access and refresh tokens, and is\n",
    "        # created automatically when the authorization flow completes for the first\n",
    "        # time.\n",
    "        if os.path.exists('token.pickle'):\n",
    "            with open('token.pickle', 'rb') as token:\n",
    "                self.creds = pickle.load(token)\n",
    "        # If there are no (valid) credentials available, let the user log in.\n",
    "        if not self.creds or not self.creds.valid:\n",
    "            if self.creds and self.creds.expired and self.creds.refresh_token:\n",
    "                self.creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    'credentials.json', self.DRIVE_SCOPES)\n",
    "                self.creds = flow.run_local_server(port=0)\n",
    "            # Save the credentials for the next run\n",
    "            with open('token.pickle', 'wb') as token:\n",
    "                pickle.dump(self.creds, token)\n",
    "\n",
    "        if self.creds == None:\n",
    "            print('ERROR : Service credentials unavailable!')\n",
    "            sys.exit()\n",
    "\n",
    "        # Start drive and docs services.\n",
    "        self.drive_service = build('drive', 'v3', credentials=self.creds)\n",
    "        self.docs_service = build('docs', 'v1', credentials=self.creds)\n",
    "\n",
    "\n",
    "\n",
    "    def pick_a_template(self):\n",
    "        \"\"\"\n",
    "        There can be a list of templated that you can pick from. Make sure you add them\n",
    "        to template list.\n",
    "        \"\"\"\n",
    "\n",
    "        title = 'covid-19_' + str(uuid.uuid1())\n",
    "        body = {\n",
    "            'name': title,\n",
    "            'description': 'Covid-19 Wiki'\n",
    "        }\n",
    "        drive_response = self.drive_service.files().copy(\n",
    "            fileId=random.choice(self.templates), body=body).execute()\n",
    "        document_copy_id = drive_response.get('id')\n",
    "        print('Dup copy ID : {0}'.format(document_copy_id))\n",
    "\n",
    "        return document_copy_id\n",
    "\n",
    "\n",
    "    def replace_a_data(self, key, value):\n",
    "        \"\"\"\n",
    "        Replace text in the document using 'key/tag'\n",
    "        \"\"\"\n",
    "        dic = {'replaceAllText': {\n",
    "                    'containsText': {\n",
    "                        'text': '{{' + key + '}}',\n",
    "                        'matchCase':  'true'\n",
    "                    },\n",
    "                    'replaceText': value,\n",
    "                }}\n",
    "        return dic\n",
    "\n",
    "\n",
    "    def insert_bullet_text(self, idx, title):\n",
    "        \"\"\"\n",
    "        Create bullets in the document.\n",
    "        \"\"\"\n",
    "\n",
    "        requests = [\n",
    "         {\n",
    "            'insertText': {\n",
    "                'location': {\n",
    "                    'index': idx,\n",
    "                },\n",
    "                'text': title\n",
    "            }},{\n",
    "                'createParagraphBullets': {\n",
    "                 'range': {\n",
    "                     'startIndex': idx,\n",
    "                     'endIndex':  idx + len(title)\n",
    "                 },\n",
    "                 'bulletPreset': 'BULLET_DIAMONDX_ARROW3D_SQUARE',\n",
    "             }\n",
    "        }]\n",
    "\n",
    "        result = self.docs_service.documents().batchUpdate(\n",
    "            documentId=doc_id, body={'requests': requests}).execute()\n",
    "\n",
    "        if result:\n",
    "            pass\n",
    "\n",
    "        return len(title)\n",
    "\n",
    "\n",
    "    def insert_text(self, idx, text):\n",
    "         \"\"\"\n",
    "         Insert raw text without formating.\n",
    "         \"\"\"\n",
    "         req = {'insertText': {\n",
    "                 'location': {\n",
    "                     'index': idx,\n",
    "                 },\n",
    "                 'text': text,\n",
    "             }}\n",
    "\n",
    "         return req, len(text)\n",
    "\n",
    "\n",
    "    def format_text(self, starti, endi, is_bold, is_italic, is_underline):\n",
    "        \"\"\"\n",
    "        Format the text as following:\n",
    "        - Bold\n",
    "        - Italic\n",
    "        \"\"\"\n",
    "        req = {'updateTextStyle': {\n",
    "                'range': {\n",
    "                    'startIndex': starti,\n",
    "                    'endIndex': endi\n",
    "                },\n",
    "                'textStyle': {\n",
    "                    'bold': is_bold,\n",
    "                    'italic': is_italic,\n",
    "                    'underline': is_underline,\n",
    "                    'weightedFontFamily': {\n",
    "                                           'fontFamily': 'Times New Roman'\n",
    "                                           },\n",
    "                    'fontSize': {\n",
    "                                'magnitude': 12,\n",
    "                                'unit': 'PT'\n",
    "                                },\n",
    "                },\n",
    "                'fields': 'bold, italic, weightedFontFamily, fontSize'\n",
    "            }}\n",
    "\n",
    "        return req\n",
    "\n",
    "\n",
    "    def hwd_batch_update(self, doc_id, requests):\n",
    "        \"\"\"\n",
    "        Batch update the document with the requests.\n",
    "        \"\"\"\n",
    "\n",
    "        result = self.docs_service.documents().batchUpdate(\n",
    "            documentId=doc_id, body={'requests': requests}).execute()\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def hwd_insert_hyperlink(self, doc_id, start_idx, end_idx, url):\n",
    "        \"\"\"\n",
    "        Insert hyperlink to the text for a given range in the\n",
    "        document body.\n",
    "        \"\"\"\n",
    "\n",
    "        requests = [\n",
    "          {\n",
    "           \"updateTextStyle\": {\n",
    "            \"textStyle\": {\n",
    "             \"link\": {\n",
    "              \"url\": url\n",
    "             }\n",
    "            },\n",
    "            \"range\": {\n",
    "             \"startIndex\": start_idx,\n",
    "             \"endIndex\": end_idx\n",
    "            },\n",
    "            \"fields\": \"link\"\n",
    "           }}\n",
    "        ]\n",
    "\n",
    "        result = self.docs_service.documents().batchUpdate(\n",
    "            documentId=doc_id, body={'requests': requests}).execute()\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def get_text_range_idx(self, doc_id, match_text):\n",
    "        \"\"\"\n",
    "        Find text and their start and end index.\n",
    "        \"\"\"\n",
    "\n",
    "        # Do a document \"get\" request and print the results as formatted JSON\n",
    "        result = self.docs_service.documents().get(documentId=doc_id).execute()\n",
    "        if DEBUG:\n",
    "            print('RX Data {0}'.format(json.dumps(result, indent=4)))\n",
    "        with open('data.json', 'w') as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "        data = result.get('body').get('content')\n",
    "        startIdx = 0\n",
    "        endIdx = 0\n",
    "\n",
    "        for d in data:\n",
    "            para = d.get('paragraph')\n",
    "            if para is None:\n",
    "                continue\n",
    "            else:\n",
    "                elements = para.get('elements')\n",
    "                for e in elements:\n",
    "                    if e.get('textRun'):\n",
    "                        content = e.get('textRun').get('content')\n",
    "                        print(' {}'.format(content))\n",
    "                        if match_text in content:\n",
    "                            print('matched')\n",
    "                            startIdx = e.get('startIndex')\n",
    "                            endIdx = e.get('endIndex')\n",
    "\n",
    "        return startIdx, endIdx\n",
    "\n",
    "\n",
    "    def insert_image(self, start_idx, url, h, w):\n",
    "        \"\"\"\n",
    "        Insert PNG, JPEG, GIF images inline, while adding text.\n",
    "        \"\"\"\n",
    "\n",
    "        request = [{\n",
    "            'insertInlineImage': {\n",
    "                'location': {\n",
    "                    'index': start_idx\n",
    "                },\n",
    "                'uri':\n",
    "                    url,\n",
    "                'objectSize': {\n",
    "                    'height': {\n",
    "                        'magnitude': h,\n",
    "                        'unit': 'PT'\n",
    "                    },\n",
    "                    'width': {\n",
    "                        'magnitude': w,\n",
    "                        'unit': 'PT'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }]\n",
    "\n",
    "        return request\n",
    "\n",
    "\n",
    "    def print_main_sections(self, doc_id, endi):\n",
    "        section_titles = ['Signs and symptoms', 'Cause', 'Diagnosis', 'Prevention']\n",
    "        requests = []\n",
    "        wr_idx = endi + 1\n",
    "\n",
    "        for s in self.covid19_wiki.sections:\n",
    "            if s.title in section_titles:\n",
    "                section_title = '\\n' + s.title + ' :\\n'\n",
    "                req, idx = self.insert_text(wr_idx, section_title)\n",
    "                requests.append(req)\n",
    "                # req = self.format_text(wr_idx, wr_idx + idx, True, False, False)\n",
    "                # requests.append(req)\n",
    "                wr_idx += idx\n",
    "                req, idx = self.insert_text(wr_idx, s.text + '\\n')\n",
    "                requests.append(req)\n",
    "                wr_idx += idx\n",
    "\n",
    "        result = self.docs_service.documents().batchUpdate(\n",
    "            documentId=doc_id, body={'requests': requests}).execute()\n",
    "\n",
    "        return result, endi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f209865-c826-44bd-9a65-14993fd3c484",
   "metadata": {},
   "source": [
    "Можно потестить, как это работает. Индекс абсолютный - соответственно, важно его учитывать при вставке, вручную это редактировать через API физически больно, но кодом следить ггораздо проще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87fc438b-bd97-4147-9055-214a28cfa5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = [\n",
    "     {\n",
    "        'insertText': {\n",
    "            'location': {\n",
    "                'index': 1,\n",
    "            },\n",
    "            'text': \"blablablabla\\n\"\n",
    "        }\n",
    "    },\n",
    "             {\n",
    "        'insertText': {\n",
    "            'location': {\n",
    "                'index': 2,\n",
    "            },\n",
    "            'text': \"uuuu\"\n",
    "        }\n",
    "    },\n",
    "             {\n",
    "        'insertText': {\n",
    "            'location': {\n",
    "                'index': 3,\n",
    "            },\n",
    "            'text': \"c\"\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "result = c_docs.docs_service.documents().batchUpdate(\n",
    "    documentId=idx, body={'requests': requests}).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcfe98-833e-43ef-892a-6657744811d2",
   "metadata": {},
   "source": [
    "Загружаем базу, если она нам нужна. Если что, у df2, df3 нет колонки new_html, тоже надо иметь в виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b6104239-3544-4e21-b514-e7302af27e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dictionary',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "dbfile = 'AS1_finvers.db'\n",
    "con = sqlite3.connect(dbfile)\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
    "\n",
    "df1 = pd.read_sql_query('SELECT new_html, lexeme FROM dictionary', con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1774b-5622-4b4a-b305-c5c5f70ca8cf",
   "metadata": {},
   "source": [
    "Мне всё удобнее делать в датафрейме, но на самом деле не супер важно, в бд всё равно как-то мало полезной инфы, кроме инфы про ударение, которой нет на многих онлайн-статьях, теперь будет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe8b699-8acd-4a39-85f8-7144bb5052f0",
   "metadata": {},
   "source": [
    "Дальше начинается зона плохого кода и костылей, потому что не так-то просто оказалось распарсить html. Сперва надо разобраться со знаками ударения. Если слово написано капсом - оно важное, в нём выделяем ударение циркумфлексом, если нет - оствляем так, но склеиваем каждый символ, заменяем на гласную с диакритикой, потому что по дефолту после отдельного знака ударения, не буквы с ним, стоит ненужный пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6aa5a63c-093b-4158-9418-0cf6e91be002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<b', 'БИРЮЗО́ВЫЙ', '/b'),\n",
       " ('/b', ', ПРИЛ; ', 'i'),\n",
       " ('<i', '-ая, -ое.', '/i')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc_strip(s):\n",
    "    \n",
    "    accents = {\"а́\": \"а\", \"е́\": \"е\", \"и́\": \"и\",\n",
    "               \"о́\": \"о\", \"у́\": \"у\", \"ы́\": \"ы\",\n",
    "               \"э́\": \"э\", \"ю́\": \"ю\", \"я́\": \"я\"}\n",
    "    \n",
    "    if s == s.upper():\n",
    "        up = True\n",
    "    else:\n",
    "        up = False\n",
    "    \n",
    "    temp = s.lower()\n",
    "    \n",
    "    for accent in accents:\n",
    "        temp = temp.replace(accent, f\"{accents[accent]}^\")\n",
    "        \n",
    "    if temp != s:\n",
    "        if up:\n",
    "            return temp.upper()\n",
    "        else:\n",
    "            return \"\".join(s)\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf5b2a-5a69-426b-8923-4e886db65e84",
   "metadata": {},
   "source": [
    "Дальше просто кусок, который я всегда копирую, когда паршу сайты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d18edadd-91a1-4bcb-9ae2-e13ec9215bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import traceback\n",
    "import ssl\n",
    "import sqlite3\n",
    "from pprint import pprint\n",
    "from fake_useragent import UserAgent\n",
    "from fp.fp import FreeProxy\n",
    "from requests import ConnectTimeout, HTTPError, Timeout, ConnectionError\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ssl.SSLContext.verify_mode = ssl.VerifyMode.CERT_OPTIONAL\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "session = requests.session()\n",
    "session.trust_env = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc90e4b-9785-4e01-ac98-59917137062a",
   "metadata": {},
   "source": [
    "Нам нужны авторы статей, что можно легко взять на самом сайте словника, храню всё в сете, как пара статья-инициалы автора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e3b600-0ae0-42e7-af20-688da52c406e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d665f9c80a44b0bd2f235bcc975226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for i in tqdm(range(50)):\n",
    "    url = f\"http://sem.ruslang.ru/slovnik.php?act=show&from={i}01&to=-1&criteria=&done=&limit=100\"\n",
    "    req = session.get(url)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    for i in soup.find_all([\"tr\"])[1::2]:\n",
    "        name = i.find(\"a\")\n",
    "        if name:\n",
    "            data.append(name.text + \"-\"+ i.find_all(\"td\")[2].text[1:-1]+\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c0089-e92d-426e-9c15-dd265bd55ce3",
   "metadata": {},
   "source": [
    "Для первого датафрейма всё обрабатывается волшебно, там все нужные секции отделяются тегом <p>, это убирает львиную долю проблем, но комменты всё равно есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "262f0d3b-ed7f-4926-8b82-32dab7767c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131ea451befa405eab32d5c77e264801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import html as h\n",
    "import regex as re\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(df1.shape[0])[536:]):\n",
    "    \n",
    "    # гугл апи ругается, если создавать доки слишком часто, приходится создавать помедленнее\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # заголовок сопоставляем с скрауленным заголовком и автором\n",
    "    sub_df = df1.iloc[i]\n",
    "    title = acc_strip(sub_df.lexeme).replace(\"^ \", \"\").lower().strip()\n",
    "    for i in data:\n",
    "        if title+\"-\" in i and i[0] == title[0]:\n",
    "            title = i\n",
    "            break\n",
    "\n",
    "    # реквест делаем заново каждый раз\n",
    "    requests = []\n",
    "    endi = 0\n",
    "    wr_idx = endi + 1\n",
    "\n",
    "    # создаём доки\n",
    "    body = {\n",
    "        'title': title\n",
    "    }\n",
    "    doc = c_docs.docs_service.documents() \\\n",
    "        .create(body=body).execute()\n",
    "\n",
    "    # id тоже сохраняем, парсим его, как хтмл\n",
    "    doc_id = doc.get('documentId')\n",
    "    sample = sub_df.new_html\n",
    "    html = BeautifulSoup(sample)\n",
    "\n",
    "    d_c = 0\n",
    "    # \n",
    "    for section in html.body.find_all(\"p\"):\n",
    "        # я ищу все теги вида <(/)*> <(/)*>\n",
    "        # почему - некоторые слова находятся вне тегов, к сожалению, парсить надо регуляркой, иначе никак\n",
    "        pattern = r\"(<[buip]|\\/[buip])>(.*?)<([buip]|\\/[buip])>\"\n",
    "        # нужны обязательно пересекающиеся теги\n",
    "        opa = re.findall(pattern, str(section), overlapped=True)\n",
    "\n",
    "        # анализируем теги вокруг и то, что между ними\n",
    "        for left, content, right in opa:\n",
    "            # пустые строки в док писать нельзя, скипаем\n",
    "            if content == \"\": continue\n",
    "            # убираем весь html-ный мусор и фиксим ударения, прибавляем\n",
    "            req, idx = c_docs.insert_text(wr_idx, acc_strip(h.unescape(content)))\n",
    "            requests.append(req)\n",
    "\n",
    "            # если надо, форматируем, по крайней мере здесь теги норм работают\n",
    "            if \"b\" in left and \"/b\" in right:\n",
    "                req = c_docs.format_text(wr_idx, wr_idx + idx, True, False, False)\n",
    "                requests.append(req)\n",
    "            elif \"i\" in left and \"/i\" in right:\n",
    "                req = c_docs.format_text(wr_idx, wr_idx + idx, False, True, False)\n",
    "                requests.append(req)\n",
    "            elif \"u\" in left and \"/u\" in right:\n",
    "                req = c_docs.format_text(wr_idx, wr_idx + idx, False, False, True)\n",
    "                requests.append(req)\n",
    "            else:\n",
    "                req = c_docs.format_text(wr_idx, wr_idx + idx, False, False, False)\n",
    "                requests.append(req)\n",
    "            wr_idx += idx\n",
    "\n",
    "        req, idx = c_docs.insert_text(wr_idx, \"\\n\")\n",
    "        requests.append(req)\n",
    "        wr_idx += idx\n",
    "\n",
    "    result = c_docs.docs_service.documents().batchUpdate(\n",
    "            documentId=doc_id, body={'requests': requests}).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbcf31-d46e-4181-8d80-56d9a87f97a0",
   "metadata": {},
   "source": [
    "Для второй и третьей бд всё гораздо веселее. Комментил только новое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166ffcd-de2e-4d3d-b8d9-54642f677b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cee073f96134363b3bac0be6671ac28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import html as h\n",
    "import regex as re\n",
    "import time\n",
    "from string import punctuation\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "for i in tqdm(range(df2.shape[0])):\n",
    "    \n",
    "    sub_df = df2.iloc[i]\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # теперь у нас нет сецкий, новые строки надо добавлять ручками, например, отделять каждый <b>\n",
    "    # но он должен быть не первый, и не пустой, это можно сделать через repl\n",
    "    def repl(match, count=[0]):\n",
    "        x, = count\n",
    "        count[0] += 1\n",
    "        if x > 0 and str(match.group(0)[-1]) != \" \":\n",
    "            return f'{str(match.group(0)[:-1])}%{str(match.group(0)[-1])}'\n",
    "        return str(match.group(0))\n",
    "\n",
    "    def repl_slash(match, count=[0]):\n",
    "        x, = count\n",
    "        count[0] += 1\n",
    "        if x > 0 and str(match.group(0)[0]) != \" \":\n",
    "            return f'{str(match.group(0)[0])}%{str(match.group(0)[1:])}'\n",
    "        return str(match.group(0))\n",
    "    \n",
    "    title = acc_strip(sub_df.lexeme).replace(\"^ \", \"\").lower().strip()\n",
    "    for i in data:\n",
    "        if title+\"-\" in i and i[0] == title[0]:\n",
    "            title = i\n",
    "            break\n",
    "\n",
    "    requests = []\n",
    "    endi = 0\n",
    "    wr_idx = endi + 1\n",
    "\n",
    "    c_docs = Covid19Docs()\n",
    "    body = {\n",
    "        'title': title\n",
    "    }\n",
    "    doc = c_docs.docs_service.documents() \\\n",
    "        .create(body=body).execute()\n",
    "    # print('Created document with title: {0}'.format(\n",
    "    #     doc.get('title')))\n",
    "\n",
    "    doc_id = doc.get('documentId')\n",
    "    sample = sub_df.html\n",
    "    html = BeautifulSoup(sample)\n",
    "    \n",
    "    html = str(html)\n",
    "    \n",
    "    # тут мне было просто лень, я заметил, что новых строк нет после определённых\n",
    "    # знаков пунктуации, пофиксил\n",
    "    html = html.replace(f\",%\", f\",\")\n",
    "    html = html.replace(f\";%\", f\",\")\n",
    "    html = re.sub(r\"%,\", f\",\", html)\n",
    "    html = re.sub(r\"%;\", f\";\", html)\n",
    "    html = re.sub(r\"% *([\\.,;:]|</[a-z]>)\", r\"\\1%\", html)\n",
    "\n",
    "    html = h.unescape(html)\n",
    "    # это цепляет %. БЛАБЛАБЛА\n",
    "    html = re.sub(r\"([\\.!?][<a-z> \\/]*)([A-ZА-Я][A-ZА-Я]+?)\", r\"\\1%\\2\", html)\n",
    "    # это цепляет % [bullet_point] БЛАБЛАБЛА\n",
    "    html = re.sub(r\"([\\.!;?][<a-z> \\/]*)([\\u2022\\u2023\\u25E6\\u2043\\u2219][<a-z> \\/])[<a-z> \\/]*([A-ZА-Я][A-ZА-Я]+?)\", r\"\\1%\\2\\3\", html)\n",
    "    # это цепляет % [A-Z]\\d [bullet_point] БЛАБЛАБЛА\n",
    "    html = re.sub(r\"([А-ЯA-Z][0-9][<a-z> \\/]*[а-я\\.]*?[<a-z> \\/]*)([<a-z> \\/]*)([\\u2022\\u2023\\u25E6\\u2043\\u2219][<a-z> \\/а-я]+)[<a-z> \\/]*([A-ZА-Я][A-ZА-Я]+?)\", r\"%\\1\\2\\3\\4\", html)\n",
    "    # одним регехом наверное можно, но ёмаё...\n",
    "    \n",
    "    # один уникальный буллетпойнт у меня не хочет обрабатываться, после него не надо новой строки\n",
    "    html = re.sub(\"(<b>)[^◊]\", repl, html)\n",
    "    html = re.sub(\"[^◊](</b>)\", repl_slash, html)\n",
    "    \n",
    "    # большая проблема - trailing whitespaces, пытался почистить, убрав пробелы перед знаками\n",
    "    for dots in [\" .\", \" ,\", \" ;\", \" :\", \" >\"]:\n",
    "        html = html.replace(dots, dots[1:])\n",
    "    \n",
    "    html = h.unescape(html)\n",
    "    html = re.sub(r\" +\", r\" \", html)\n",
    "    html = re.sub(r\"%<\\/b>[<a-z> \\/]*?‘\", \"</b> ‘\", html)\n",
    "    html = re.sub(r\"%<\\/b>[<a-z> \\/]*?,\", \"</b>,\", html)\n",
    "    html = re.sub(r\"%<\\/b>[<a-z> \\/]*?;\", \"</b>;\", html)\n",
    "    \n",
    "    # убираю пустые теги\n",
    "    html = html.replace(\"<i> </i>\", \"\")\n",
    "    html = html.replace(\"%</b> <b>%\", \"</b> <b> \")\n",
    "    \n",
    "    html = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    d_c = 0\n",
    "    section = html\n",
    "    pattern = r\"(<[buip]|\\/[buip])>(.*?)<([buip]|\\/[buip])>\"\n",
    "    opa = re.findall(pattern, str(section), overlapped=True)\n",
    "    b_i = section.find_all([\"b\", \"i\"], text=True, recursive=False)\n",
    "    default = section.find_all(text=True, recursive=False)\n",
    "\n",
    "    not_first_b = 0\n",
    "    for left, content, right in opa:\n",
    "        # в некоторых доках много мусора про ссылку на сам словарь, это не пишем\n",
    "        if \"Научное изданиеАктивный словАрь русского языкА\" in content:\n",
    "            print(\"STAPH!\")\n",
    "            break\n",
    "        else:\n",
    "            # все процентики я преобразую в новые строки, почему-то нормально новые строки не вставляются\n",
    "            content = re.sub(\"%+\", \"%\", content)\n",
    "            content = re.sub(\" +\", \" \", content)\n",
    "            content = content.replace(\"%\", \"\\n\")\n",
    "            if content == \"\" or content == \" \":\n",
    "                continue\n",
    "            content = h.unescape(content)\n",
    "            req, idx = c_docs.insert_text(wr_idx, acc_strip(content))\n",
    "            requests.append(req)\n",
    "\n",
    "            if \"b\" in left and \"/b\" in right:\n",
    "                req = c_docs.format_text(wr_idx, wr_idx + idx, True, False, False)\n",
    "                requests.append(req)\n",
    "            elif \"i\" in left and \"/i\" in right:\n",
    "                req = c_docs.format_text(wr_idx, wr_idx + idx, False, True, False)\n",
    "                requests.append(req)\n",
    "            elif \"u\" in left and \"/u\" in right:\n",
    "                req = c_docs.format_text(wr_idx, wr_idx + idx, False, False, True)\n",
    "                requests.append(req)\n",
    "            else:\n",
    "                req = c_docs.format_text(wr_idx, wr_idx + idx, False, False, False)\n",
    "                requests.append(req)\n",
    "            wr_idx += idx\n",
    "\n",
    "    req, idx = c_docs.insert_text(wr_idx, \"\\n\")\n",
    "    requests.append(req)\n",
    "    wr_idx += idx\n",
    "    \n",
    "    result = c_docs.docs_service.documents().batchUpdate(\n",
    "            documentId=doc_id, body={'requests': requests}).execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
